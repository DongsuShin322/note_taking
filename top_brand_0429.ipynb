{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스타벅스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty DataFrame 생성\n",
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타벅스 매장 찾기\n",
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('https://www.istarbucks.co.kr/store/store_map.do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역 검색\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"container\"]/div/form/fieldset/div/section/article[1]/article/header[2]/h3/a\"\"\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 페이지 파싱\n",
    "bs = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17개 시도\n",
    "sido_list = []\n",
    "for temp in bs.find('ul', class_='sido_arae_box').find_all('a'):\n",
    "    sido_list.append(temp.text)\n",
    "print (sido_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 시도에 접근\n",
    "for i in range(1, len(sido_list)+1):\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"container\"]/div/form/fieldset/div/section/article[1]/article/article[2]/div[1]/div[2]/ul/li[{}]/a\"\"\".format(i)).click()\n",
    "    time.sleep(1)\n",
    "    if not i == len(sido_list): # i = 17(세종)은 전체 클릭 필요X\n",
    "        # 전체 클릭\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"mCSB_2_container\"]/ul/li[1]/a\"\"\").click()\n",
    "        time.sleep(1)\n",
    "    sido_bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(3)\n",
    "    li_list = sido_bs.find('ul', class_='quickSearchResultBoxSidoGugun').find_all('li')\n",
    "    for li in li_list:\n",
    "        name = li.attrs['data-name']\n",
    "        info = li.find('p').contents\n",
    "        addr = info[0]\n",
    "        tel = info[2]\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    print ('{} is done'.format(sido_list[i-1]))\n",
    "    # 지역 검색\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"container\"]/div/form/fieldset/div/section/article[1]/article/header[2]/h3/a\"\"\").click()\n",
    "    time.sleep(1)\n",
    "print (df.shape)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이디야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 이디야 매장 찾기\n",
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('https://www.ediya.com/contents/find_store.html#c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소로 찾기\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"contentWrap\"]/div[3]/div/div[2]/ul/li[2]/a\"\"\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seoul = ['서울 종로구','서울 중구','서울 용산구','서울 성동구','서울 광진구',\n",
    "'서울 동대문구','서울 중랑구','서울 성북구','서울 강북구','서울 도봉구',\n",
    "'서울 노원구','서울 은평구','서울 서대문구','서울 마포구','서울 양천구',\n",
    "'서울 강서구','서울 구로구','서울 금천구','서울 영등포구','서울 동작구',\n",
    "'서울 관악구','서울 서초구','서울 강남구','서울 송파구','서울 강동구']\n",
    "\n",
    "Busan = ['부산 중구','부산 서구','부산 동구','부산 영도구','부산 부산진구',\n",
    "         '부산 동래구','부산 남구','부산 북구','부산 강서구','부산 해운대구',\n",
    "         '부산 사하구','부산 금정구','부산 연제구','부산 수영구','부산 사상구',\n",
    "         '부산 기장군']\n",
    "\n",
    "Daegu = ['대구 중구','대구 동구','대구 남구','대구 북구',\n",
    "         '대구 수성구','대구 달서구','대구 달성군']\n",
    "\n",
    "Incheon = ['인천 중구','인천 동구','인천 미추홀구','인천 연수구','인천 남동구',\n",
    "           '인천 부평구','인천 계양구','인천 서구','인천 강화군','인천 옹진군']\n",
    "\n",
    "Gwangju = ['광주 동구','광주 서구','광주 남구','광주 북구','광주 광산구']\n",
    "\n",
    "Daejeon = ['대전']\n",
    "\n",
    "Ulsan = ['울산 중구','울산 남구','울산 동구','울산 북구','울산 울주군']\n",
    "\n",
    "Sejong = ['세종특별자치시']\n",
    "\n",
    "Gyeonggi = ['경기도','경기 수원시 장안구','경기 수원시 팔달구','경기 수원시 권선구',\n",
    "            '경기 수원시 영통구','경기 성남시 수정구','경기 성남시 중원구',\n",
    "            '경기 성남시 분당구','경기 안양시','경기 안산시','경기 용인시 처인구',\n",
    "            '경기 용인시 기흥구','경기 용인시 수지구','경기 광명시','경기 평택시',\n",
    "            '경기 과천시','경기 오산시','경기 시흥시','경기 군포시','경기 의왕시',\n",
    "            '경기 하남시','경기 이천시','경기 안성시','경기 김포시','경기 화성시',\n",
    "            '경기 광주시','경기 여주시','경기 부천시','경기 양평군','경기 고양시 덕양구',\n",
    "            '경기 고양시 일산동구','경기 고양시 일산서구','경기 의정부시','경기 동두천시',\n",
    "            '경기 구리시','경기 남양주시','경기 파주시','경기 양주시','경기 포천시',\n",
    "            '경기 연천군','경기 가평군']\n",
    "\n",
    "Gangwon = ['강원 춘천시','강원 원주시','강원 강릉시','강원 동해시','강원 속초시',\n",
    "           '강원 삼척시','강원 홍천군','강원 평창군','강원 정선군','강원 철원군',\n",
    "           '강원 화천군','강원 양구군','강원 인제군','강원 고성군','강원 양양군']\n",
    "\n",
    "Choongbook = ['충북 청주시','충북 충주시','충북 제천시','충북 보은군','충북 옥천군',\n",
    "              '충북 영동군','충북 진천군','충북 괴산군','충북 음성군','충북 단양군',\n",
    "              '충북 증평군']\n",
    "\n",
    "Choongnam = ['충남 천안시','충남 공주시','충남 보령시','충남 아산시','충남 서산시',\n",
    "             '충남 논산시','충남 당진시','충남 금산군','충남 부여군','충남 서천군',\n",
    "             '충남 홍성군','충남 예산군','충남 태안군']\n",
    "\n",
    "Jeonbook = ['전북 전주시','전북 군산시','전북 익산시','전북 정읍시','전북 남원시',\n",
    "            '전북 김제시','전북 완주군','전북 진안군','전북 무주군','전북 장수군',\n",
    "            '전북 임실군','전북 순창군','전북 고창군','전북 부안군']\n",
    "\n",
    "Jeonnam = ['전남 목포시','전남 여수시','전남 순천시','전남 나주시','전남 광양시',\n",
    "           '전남 담양군','전남 곡성군','전남 고흥군','전남 화순군','전남 장흥군',\n",
    "           '전남 강진군','전남 해남군','전남 영암군','전남 무안군','전남 영광군',\n",
    "           '전남 장성군','전남 완도군','전남 진도군']\n",
    "\n",
    "Gyeongbook = ['경북 포항시','경북 경주시','경북 김천시','경북 안동시','경북 구미시',\n",
    "              '경북 영주시','경북 영천시','경북 상주시','경북 문경시','경북 경산시',\n",
    "              '경북 청송군','경북 영덕군','경북 청도군','경북 고령군','경북 성주군',\n",
    "              '경북 칠곡군','경북 예천군','경북 봉화군','경북 울진군']\n",
    "\n",
    "Gyeongnam = ['경남 창원시','경남 진주시','경남 통영시','경남 사천시','경남 김해시',\n",
    "             '경남 밀양시','경남 거제시','경남 양산시','경남 함안군','경남 창녕군',\n",
    "             '경남 고성군','경남 남해군','경남 산청군','경남 함양군','경남 거창군',\n",
    "             '경남 합천군']\n",
    "\n",
    "Jeju = ['제주특별자치도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "united = Seoul + Busan + Daegu + Incheon + Gwangju + Daejeon + Ulsan + Sejong + Gyeonggi \\\n",
    " + Gangwon + Choongbook + Choongnam + Jeonbook + Jeonnam + Gyeongbook + Gyeongnam + Jeju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty DataFrame 생성\n",
    "df = pd.DataFrame(columns=['name','addr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 입력\n",
    "text_area = driver.find_element_by_xpath(\"\"\"//*[@id=\"keyword\"]\"\"\")\n",
    "num = 1\n",
    "for u in united:\n",
    "    text_area.send_keys(u)\n",
    "    text_area.submit()\n",
    "    time.sleep(0.5)\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(3)\n",
    "    for i in bs.find_all('li', class_='item'):\n",
    "        name = i.find('dt').text\n",
    "        addr = i.find('dd').text\n",
    "        df = df.append({'name':name, 'addr':addr}, ignore_index=True)\n",
    "    text_area.clear()\n",
    "    print ('{} - finished'.format(u))\n",
    "    num += 1\n",
    "    \n",
    "    if num % 20 == 0:\n",
    "        time.sleep(10)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/ediya.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CU 매장 찾기\n",
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('http://cu.bgfretail.com/store/list.do?category=store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 페이지 파싱\n",
    "bs = BeautifulSoup(driver.page_source, 'html.parser') # 1페이지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "n_th = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_page = len(bs.find('ul',class_='pagination').find_all('a'))\n",
    "num_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty DataFrame 생성\n",
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while num_page == 9:\n",
    "    name_list = []\n",
    "    tel_list = []\n",
    "    addr_list = []\n",
    "    \n",
    "    for name in bs.find_all('span', class_='name'):\n",
    "        name_list.append(name.text)\n",
    "    for tel in bs.find_all('span', class_='tel'):\n",
    "        tel_list.append(tel.text)\n",
    "    for addr in bs.find_all('address'):\n",
    "        addr_list.append(addr.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    for i in range(len(name_list)):\n",
    "        df = df.append({'name':name_list[i], 'addr':addr_list[i], 'tel':tel_list[i]}, ignore_index=True)\n",
    "    \n",
    "    print (\"{}-page is finished\".format(page))\n",
    "    \n",
    "    page += 1\n",
    "    n_th += 1\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"paging\"]/ul/a[{}]\"\"\".format(n_th+2)).click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if n_th == 6:\n",
    "        n_th = 1\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        time.sleep(3)\n",
    "        num_page = len(bs.find('ul',class_='pagination').find_all('a'))\n",
    "    else:\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        time.sleep(3)\n",
    "        \n",
    "    if page % 20 == 0:\n",
    "        time.sleep(5)\n",
    "    if page % 50 == 0:\n",
    "        time.sleep(7)\n",
    "    if page % 100 == 0:\n",
    "        time.sleep(10)\n",
    "    \n",
    "    if page == 13:\n",
    "        break\n",
    "    \n",
    "if page == 2656:\n",
    "    name_list = []\n",
    "    tel_list = []\n",
    "    addr_list = []\n",
    "    \n",
    "    for name in bs.find_all('span', class_='name'):\n",
    "        name_list.append(name.text)\n",
    "    for tel in bs.find_all('span', class_='tel'):\n",
    "        tel_list.append(tel.text)\n",
    "    for addr in bs.find_all('address'):\n",
    "        addr_list.append(addr.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    for i in range(len(name_list)):\n",
    "        df = df.append({'name':name_list[i], 'addr':addr_list[i], 'tel':tel_list[i]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세븐일레븐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세븐일레븐 매장 찾기\n",
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('http://www.7-eleven.co.kr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매장찾기\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"header\"]/div/div/div[1]/a[1]\"\"\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sido = Select(driver.find_element_by_id(\"storeLaySido\"))\n",
    "num_sido = len(select_sido.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, num_sido):\n",
    "    select_sido = Select(driver.find_element_by_id(\"storeLaySido\"))\n",
    "    time.sleep(0.1)\n",
    "    select_sido.select_by_index(i)\n",
    "    time.sleep(1)\n",
    "    select_gu = Select(driver.find_element_by_id(\"storeLayGu\"))\n",
    "    time.sleep(0.1)\n",
    "    num_gu = len(select_gu.options)\n",
    "    for j in range(1, num_gu):\n",
    "        select_gu = Select(driver.find_element_by_id(\"storeLayGu\"))\n",
    "        time.sleep(0.1)\n",
    "        select_gu.select_by_index(j)\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"storeButton1\"]\"\"\").click()\n",
    "        time.sleep(1)\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        time.sleep(3)\n",
    "        temp = 0\n",
    "        for t in bs.find('div',class_='list_stroe').find_all('span'):\n",
    "            temp += 1\n",
    "            if temp % 3 == 1:\n",
    "                name = t.text.replace(\"\\n\",\"\")\n",
    "                name = name.replace(\"\\t\",\"\")\n",
    "            elif temp % 3 == 2:\n",
    "                addr = t.text.replace(\"\\n\",\"\")\n",
    "            else:\n",
    "                df = df.append({'name':name, 'addr':addr}, ignore_index=True)\n",
    "        if j % 10 == 0:\n",
    "            time.sleep(5)\n",
    "    time.sleep(10)\n",
    "# 세종특별자치시는 구/군 index 1이 없어서 안되므로 추가 작업 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=df.name\n",
    "s2 = df['addr'].map(lambda x : x.replace('\\xa0', ' '))\n",
    "new_df = pd.DataFrame({'name':s1, 'addr':s2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/seveneleven.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 온누리약국"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://www.onnuri.co.kr/store/store_01_sub.jsp?field=store_name&field_value=&store_name=&add1=&city_s_name=&city_l_name=&goo_name=&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,206):\n",
    "    new_url = base_url + str(i)\n",
    "    req = requests.get(new_url)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    for s in soup.find_all('table', attrs={'height':30}):\n",
    "        name = s.find_all('td')[1].text\n",
    "        name = name.replace('\\n','').replace('\\r','').replace('\\t','').strip()\n",
    "        addr = s.find_all('td')[3].text\n",
    "        tel = s.find_all('td')[4].text\n",
    "        tel = tel.replace('\\n','').strip()\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    print ('{} is finished'.format(i))\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        time.sleep(2)\n",
    "    if i % 50 == 0:\n",
    "        time.sleep(5)\n",
    "    if i % 100 == 0:\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/onnuri.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파리바게트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.paris.co.kr/shop/search.jsp?s_sido={}&s_gugun=&s_name='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sido = ['강원도','경기도','경상남도','경상북도','광주광역시','대구광역시','대전광역시',\n",
    "        '부산광역시','서울특별시','세종특별자치시','울산광역시','인천광역시','전라남도',\n",
    "        '전라북도','제주특별자치도','충청남도','충청북도']\n",
    "print (\"시/도 개수 :\",len(sido))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sido)):\n",
    "    print (sido[i])\n",
    "    req = requests.get(base_url.format(sido[i]))\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    num_store = len(soup.find('div', class_='shop_list_box').find_all('strong'))\n",
    "    print ('매장 수 :',num_store)\n",
    "    for s in range(num_store):\n",
    "        info = soup.find('div', class_='shop_list_box')\n",
    "        name = info.find_all('strong')[s].text\n",
    "        name = name.replace('\\r','').replace('\\n','').replace('\\t','').strip()\n",
    "        addr = info.find_all('p')[s].contents[0]\n",
    "        addr = addr.replace('\\r','').replace('\\n','').replace('\\t','').strip()\n",
    "        tel = info.find_all('p')[s].contents[2]\n",
    "        tel = tel.replace('\\r','').replace('\\n','').replace('\\t','').strip()\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    print ('-----------------------------------------------')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/parisbaguette.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니스톱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('https://www.ministop.co.kr/MiniStopHomePage/page/store/store.do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banner close\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"floatbanner\"]/div[1]/span[2]\"\"\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select box\n",
    "select_sido = Select(driver.find_element_by_id(\"area1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sido = len(select_sido.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (num_sido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,num_sido):\n",
    "    select_sido = Select(driver.find_element_by_id(\"area1\"))\n",
    "    time.sleep(1)\n",
    "    select_sido.select_by_index(i)\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"section\"]/div[3]/div/div[2]/div[2]/div[1]/a\"\"\").click()\n",
    "    time.sleep(2)\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(3)\n",
    "    info = bs.find('div', class_='area').find_all('li')\n",
    "    for j in info:\n",
    "        name = j.contents[0]\n",
    "        name = name.replace('\\n','').replace('\\t','').strip()\n",
    "        addr = j.contents[2]\n",
    "        addr = addr.replace('\\n','').replace('\\t','').strip()\n",
    "        tel = j.contents[4]\n",
    "        tel = tel.replace('\\n','').replace('\\t','').strip()\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/ministop.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크린토피아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('http://www.cleantopia.com/kr/store/storeList.do')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1페이지 먼저 수행\n",
    "bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "time.sleep(3)\n",
    "for b in bs.find_all('div',class_='item'):\n",
    "    name = b.find('span', class_='name').text\n",
    "    addr = b.find_all('em')[0].text\n",
    "    tel = b.find_all('em')[1].text\n",
    "    df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2페이지부터 272 페이지까지 (다음페이지 버튼 271번 클릭)\n",
    "# 클릭 후 파싱\n",
    "for i in range(271):\n",
    "    print (\"{} page is done\".format(i+1))\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"content\"]/div[4]/div/div[2]/div[1]/div[2]/div[2]/a[3]\"\"\").click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(3)\n",
    "    for b in bs.find_all('div',class_='item'):\n",
    "        name = b.find('span', class_='name').text\n",
    "        addr = b.find_all('em')[0].text\n",
    "        tel = b.find_all('em')[1].text\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        time.sleep(10)\n",
    "        \n",
    "    elif i % 20 == 0:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=df.name\n",
    "s2 = df['addr'].map(lambda x : x.replace('\\xa0', ' '))\n",
    "s3 = df.tel\n",
    "new_df = pd.DataFrame({'name':s1, 'addr':s2, 'tel':s3})\n",
    "new_df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/cleantopia.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 본죽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('https://www.bonif.co.kr/store/list?brdCd=BF101')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sido = Select(driver.find_element_by_id(\"sido\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sido = len(select_sido.options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,num_sido):\n",
    "    select_sido = Select(driver.find_element_by_id(\"sido\"))\n",
    "    select_sido.select_by_index(i)\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"storeC01\"]/div/a/img\"\"\").click()\n",
    "    time.sleep(2)\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(2)\n",
    "    for t in bs.find('ul', class_='my-store-list').find_all('li'):\n",
    "        name = t.find('span',class_='store-area').text\n",
    "        addr = t.find('p').contents[0]\n",
    "        tel = t.find('p').contents[-1].text\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop_duplicates()\n",
    "new_df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/bonjook.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 롯데리아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('http://www.lotteria.com/Shop/Shop_List.asp?SearchIs24H=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"frmNavi\"]/div/fieldset/div[2]/span/a\"\"\").click()\n",
    "time.sleep(1)\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"devCallShopList\"]/div[2]/span/a[3]\"\"\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','tel'])\n",
    "next_click = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(next_click):\n",
    "    for j in [3,3,4,5,6,7,8,9,10,11]:\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"devCallShopList\"]/div[2]/span/a[{}]\"\"\".format(j)).click()\n",
    "        time.sleep(10)\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        time.sleep(3)\n",
    "        for b in bs.find_all('tr', class_='shopSearch'):\n",
    "            name = b.find('td', class_='first num').text\n",
    "            tel = b.find_all('td')[2].text\n",
    "            df = df.append({'name':name, 'tel':tel}, ignore_index=True)\n",
    "        print ('done')\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"devCallShopList\"]/div[2]/span/a[12]\"\"\").click()\n",
    "    print ('next clicked')\n",
    "    time.sleep(10)\n",
    "print ('130 pages done')\n",
    "for j in [3,3,4,5]:\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"devCallShopList\"]/div[2]/span/a[{}]\"\"\".format(j)).click()\n",
    "    time.sleep(10)\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(3)\n",
    "    for b in bs.find_all('tr', class_='shopSearch'):\n",
    "        name = b.find('td', class_='first num').text\n",
    "        tel = b.find_all('td')[2].text\n",
    "        df = df.append({'name':name, 'tel':tel}, ignore_index=True)\n",
    "    print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/lotteria.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 해법영어교실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('http://www.hbenglish.co.kr/hbenglish/SearchClass.aspx?Code=010502')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','tel','addr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_area = driver.find_element_by_xpath(\"\"\"//*[@id=\"SearchWord\"]\"\"\")\n",
    "text_area.send_keys(\"서울\")\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"map_right2\"]/div/li/a\"\"\").click()\n",
    "time.sleep(2)\n",
    "text_area = driver.find_element_by_xpath(\"\"\"//*[@id=\"ctl00_ContentPlaceHolder1_SearchWord\"]\"\"\")\n",
    "text_area.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1 ~ 10 page\n",
    "for i in range(1,11):\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(2)\n",
    "    for b in bs.find_all('table', class_='map_addressRow'):\n",
    "        name = b.find_all('td')[0].text\n",
    "        tel = b.find_all('td')[1].text\n",
    "        addr = b.find_all('td')[2].text\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"ctl00_ContentPlaceHolder1_PageNumber\"]/span[{}]/a\"\"\".format(i+1)).click()\n",
    "    time.sleep(3)\n",
    "print ('10 pages')\n",
    "    \n",
    "# 11 ~ 100page\n",
    "for k in range(9):\n",
    "    for j in range(3,13):\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        time.sleep(2)\n",
    "        for b in bs.find_all('table', class_='map_addressRow'):\n",
    "            name = b.find_all('td')[0].text\n",
    "            tel = b.find_all('td')[1].text\n",
    "            addr = b.find_all('td')[2].text\n",
    "            df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"ctl00_ContentPlaceHolder1_PageNumber\"]/span[{}]/a\"\"\".format(j+1)).click()\n",
    "        time.sleep(3)\n",
    "    print ('10 pages')    \n",
    "print ('100 pages done')\n",
    "for m in range(3,12):\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(2)\n",
    "    for b in bs.find_all('table', class_='map_addressRow'):\n",
    "        name = b.find_all('td')[0].text\n",
    "        tel = b.find_all('td')[1].text\n",
    "        addr = b.find_all('td')[2].text\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)\n",
    "    if m != 11:\n",
    "        driver.find_element_by_xpath(\"\"\"//*[@id=\"ctl00_ContentPlaceHolder1_PageNumber\"]/span[{}]/a\"\"\".format(m+1)).click()\n",
    "        time.sleep(3)\n",
    "print ('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:/Users/ds.sin/Desktop/Top_brand/haebubEnglish.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 페리카나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name','addr','tel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='www.pelicana.co.kr', port=443): Max retries exceeded with url: /store/stroe_search.html?page=114&branch_name=&gu=&si= (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\")))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 \u001b[0mcnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1906\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1907\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m             \u001b[0m_raise_current_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\_util.py\u001b[0m in \u001b[0;36mexception_from_error_queue\u001b[1;34m(exception_type)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             ssl_context=context)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad handshake: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: (\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\",)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.pelicana.co.kr', port=443): Max retries exceeded with url: /store/stroe_search.html?page=114&branch_name=&gu=&si= (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\")))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d374808e818d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.pelicana.co.kr/store/stroe_search.html?page={}&branch_name=&gu=&si=\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m114\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[1;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='www.pelicana.co.kr', port=443): Max retries exceeded with url: /store/stroe_search.html?page=114&branch_name=&gu=&si= (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\")))"
     ]
    }
   ],
   "source": [
    "url = \"https://www.pelicana.co.kr/store/stroe_search.html?page={}&branch_name=&gu=&si=\".format(114)\n",
    "req = requests.get(url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, 115):\n",
    "    url = \"https://www.pelicana.co.kr/store/stroe_search.html?page={}&branch_name=&gu=&si=\".format(page)\n",
    "    req = requests.get(url)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    for s in soup.find_all('table', attrs={'height':30}):\n",
    "        name = s.find_all('td')[1].text\n",
    "        name = name.replace('\\n','').replace('\\r','').replace('\\t','').strip()\n",
    "        addr = s.find_all('td')[3].text\n",
    "        tel = s.find_all('td')[4].text\n",
    "        tel = tel.replace('\\n','').strip()\n",
    "        df = df.append({'name':name, 'addr':addr, 'tel':tel}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 투다리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/ds.sin/Desktop/Python/crawling/chromedriver')\n",
    "driver.get('http://tudari.co.kr/매장찾기/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>\n",
       "<a href=\"http://tudari.co.kr/%eb%a7%a4%ec%9e%a5%ec%b0%be%ea%b8%b0/?uid=1844\" title=\"인하대역점\">인하대역점</a>\n",
       "<a class=\"mobile_tel\" href=\"tel:032-891-0542\">032-891-0542</a>\n",
       "</td>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[1].find_all('td')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인하대역점'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[1].find_all('td')[2].contents[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n인천 미추홀구 독배로 311\\xa0114호 (용현동, 비젼프라자) '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[1].find_all('td')[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'032-891-0542'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[1].find_all('td')[4].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대평동점'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[19].find_all('td')[2].contents[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n세종특별자치시 한누리대로 2236\\xa0상가동 1층 A 130호 '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[19].find_all('td')[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find('table', class_='map_list').find('tbody').find_all('tr')[19].find_all('td')[4].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
